2020-11-03 16:43:17.357193: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-03 16:43:17.380023: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2799925000 Hz
2020-11-03 16:43:17.380711: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x85872e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-03 16:43:17.380759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-03 16:43:17.383075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-11-03 16:43:17.443740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.444106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8398860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-11-03 16:43:17.444155: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050, Compute Capability 6.1
2020-11-03 16:43:17.444524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.444903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-11-03 16:43:17.444953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-03 16:43:17.446588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-11-03 16:43:17.448136: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-03 16:43:17.448636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-03 16:43:17.450354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-03 16:43:17.451426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-03 16:43:17.454810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-03 16:43:17.455046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.455417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.455627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-11-03 16:43:17.455681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-03 16:43:17.833020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-03 16:43:17.833069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-11-03 16:43:17.833076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-11-03 16:43:17.833393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.833908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:43:17.834265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1338 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
<models.gpt2_model.GPT2Model object at 0x7f8f3c08cc18>
Tokenizing and building vocabulary for code snippets and queries.  This step may take several hours.
2020-11-03 16:44:37.674414: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Some layers from the model checkpoint at gpt2 were not used when initializing TFGPT2Model: ['h_._10/ln_2/gamma:0', 'h_._5/attn/c_proj/bias:0', 'h_._0/attn/c_attn/weight:0', 'h_._0/attn/c_proj/bias:0', 'h_._8/mlp/c_proj/weight:0', 'h_._6/attn/c_attn/weight:0', 'h_._9/mlp/c_proj/bias:0', 'h_._7/attn/c_proj/bias:0', 'h_._10/mlp/c_proj/weight:0', 'h_._10/mlp/c_proj/bias:0', 'h_._3/ln_1/gamma:0', 'h_._8/attn/c_proj/weight:0', 'ln_f/beta:0', 'h_._5/ln_1/beta:0', 'h_._11/ln_1/gamma:0', 'h_._8/ln_1/beta:0', 'h_._10/attn/c_attn/weight:0', 'h_._0/attn/c_attn/bias:0', 'h_._10/mlp/c_fc/weight:0', 'h_._5/ln_1/gamma:0', 'h_._11/ln_2/beta:0', 'h_._2/mlp/c_proj/weight:0', 'h_._7/mlp/c_proj/weight:0', 'h_._3/attn/c_attn/weight:0', 'h_._8/mlp/c_proj/bias:0', 'h_._10/attn/c_proj/bias:0', 'h_._7/attn/c_attn/weight:0', 'h_._9/ln_2/beta:0', 'h_._7/ln_2/beta:0', 'h_._8/attn/c_proj/bias:0', 'h_._8/mlp/c_fc/bias:0', 'h_._1/mlp/c_fc/bias:0', 'h_._6/ln_2/beta:0', 'h_._10/ln_1/gamma:0', 'h_._11/attn/c_attn/bias:0', 'h_._3/mlp/c_proj/weight:0', 'h_._1/attn/c_proj/bias:0', 'h_._2/ln_1/beta:0', 'wpe/embeddings:0', 'h_._6/attn/c_proj/bias:0', 'h_._10/attn/c_attn/bias:0', 'h_._5/mlp/c_proj/weight:0', 'h_._6/ln_1/beta:0', 'h_._11/attn/c_proj/weight:0', 'h_._11/mlp/c_fc/bias:0', 'h_._1/ln_1/gamma:0', 'h_._10/ln_2/beta:0', 'h_._8/attn/c_attn/weight:0', 'h_._4/mlp/c_fc/bias:0', 'h_._0/mlp/c_proj/weight:0', 'h_._7/ln_1/beta:0', 'h_._9/attn/c_proj/weight:0', 'h_._4/attn/c_attn/bias:0', 'h_._6/mlp/c_fc/weight:0', 'h_._0/mlp/c_fc/bias:0', 'h_._5/mlp/c_fc/bias:0', 'h_._2/mlp/c_fc/bias:0', 'h_._4/attn/c_proj/bias:0', 'h_._1/ln_2/gamma:0', 'h_._5/attn/c_proj/weight:0', 'h_._6/mlp/c_proj/bias:0', 'h_._3/ln_2/gamma:0', 'h_._2/attn/c_attn/bias:0', 'h_._1/attn/c_attn/weight:0', 'h_._11/attn/c_proj/bias:0', 'h_._8/mlp/c_fc/weight:0', 'h_._11/ln_1/beta:0', 'h_._0/mlp/c_fc/weight:0', 'h_._11/mlp/c_proj/weight:0', 'h_._5/ln_2/beta:0', 'h_._9/ln_1/gamma:0', 'h_._5/mlp/c_fc/weight:0', 'h_._5/attn/c_attn/weight:0', 'h_._2/attn/c_proj/bias:0', 'h_._8/attn/c_attn/bias:0', 'h_._7/mlp/c_fc/weight:0', 'wte/weight:0', 'h_._2/mlp/c_fc/weight:0', 'h_._7/attn/c_attn/bias:0', 'h_._1/mlp/c_fc/weight:0', 'h_._4/ln_1/gamma:0', 'h_._2/attn/c_proj/weight:0', 'h_._5/ln_2/gamma:0', 'h_._5/attn/c_attn/bias:0', 'h_._3/mlp/c_fc/bias:0', 'h_._6/attn/c_proj/weight:0', 'h_._9/ln_2/gamma:0', 'h_._3/ln_2/beta:0', 'h_._8/ln_2/beta:0', 'h_._2/mlp/c_proj/bias:0', 'h_._11/mlp/c_proj/bias:0', 'h_._0/attn/c_proj/weight:0', 'h_._0/ln_2/gamma:0', 'h_._4/mlp/c_proj/bias:0', 'h_._6/attn/c_attn/bias:0', 'h_._10/ln_1/beta:0', 'h_._4/attn/c_attn/weight:0', 'h_._3/ln_1/beta:0', 'h_._9/attn/c_proj/bias:0', 'h_._2/ln_2/beta:0', 'h_._4/mlp/c_proj/weight:0', 'h_._2/ln_2/gamma:0', 'h_._6/mlp/c_fc/bias:0', 'h_._1/ln_1/beta:0', 'h_._2/ln_1/gamma:0', 'h_._4/mlp/c_fc/weight:0', 'h_._8/ln_1/gamma:0', 'h_._1/mlp/c_proj/bias:0', 'h_._9/attn/c_attn/bias:0', 'h_._11/ln_2/gamma:0', 'h_._8/ln_2/gamma:0', 'h_._10/attn/c_proj/weight:0', 'h_._11/mlp/c_fc/weight:0', 'h_._7/mlp/c_proj/bias:0', 'h_._7/ln_2/gamma:0', 'h_._4/attn/c_proj/weight:0', 'h_._7/ln_1/gamma:0', 'h_._5/mlp/c_proj/bias:0', 'h_._3/attn/c_attn/bias:0', 'h_._0/ln_1/beta:0', 'h_._3/attn/c_proj/weight:0', 'h_._11/attn/c_attn/weight:0', 'h_._0/mlp/c_proj/bias:0', 'h_._2/attn/c_attn/weight:0', 'h_._1/mlp/c_proj/weight:0', 'h_._1/ln_2/beta:0', 'h_._0/ln_2/beta:0', 'h_._3/mlp/c_fc/weight:0', 'h_._1/attn/c_proj/weight:0', 'h_._6/mlp/c_proj/weight:0', 'h_._9/ln_1/beta:0', 'h_._7/mlp/c_fc/bias:0', 'ln_f/gamma:0', 'h_._3/attn/c_proj/bias:0', 'h_._3/mlp/c_proj/bias:0', 'h_._9/mlp/c_fc/bias:0', 'h_._0/ln_1/gamma:0', 'h_._4/ln_2/beta:0', 'h_._9/attn/c_attn/weight:0', 'h_._7/attn/c_proj/weight:0', 'h_._10/mlp/c_fc/bias:0', 'h_._1/attn/c_attn/bias:0', 'h_._6/ln_1/gamma:0', 'h_._4/ln_1/beta:0', 'h_._9/mlp/c_fc/weight:0', 'h_._4/ln_2/gamma:0', 'h_._9/mlp/c_proj/weight:0', 'h_._6/ln_2/gamma:0']
- This IS expected if you are initializing TFGPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing TFGPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some layers of TFGPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['gpt2_encoder/tfgp_t2model/transformer/h_._7/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/ln_f/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/ln_f/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/wpe/embeddings:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/attn/c_attn/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._0/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/ln_2/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._6/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/attn/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/mlp/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._8/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._5/attn/c_proj/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._1/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/mlp/c_fc/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._7/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/ln_2/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/wte/weight:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._4/mlp/c_fc/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._9/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/ln_1/beta:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._10/mlp/c_proj/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._3/ln_1/gamma:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._11/attn/c_attn/bias:0', 'gpt2_encoder/tfgp_t2model/transformer/h_._2/mlp/c_proj/weight:0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
WARNING:tensorflow:From /mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/src/utils/tfutils.py:144: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.
WARNING:tensorflow:Tensor._shape is private, use Tensor.shape instead. Tensor._shape will eventually be removed.
[<tf.Tensor 'code_encoder/python/gpt2_encoder/truediv_1:0' shape=(None, 768) dtype=float32>]
Some layers from the model checkpoint at gpt2 were not used when initializing TFGPT2Model: ['h_._10/ln_2/gamma:0', 'h_._5/attn/c_proj/bias:0', 'h_._0/attn/c_attn/weight:0', 'h_._0/attn/c_proj/bias:0', 'h_._8/mlp/c_proj/weight:0', 'h_._6/attn/c_attn/weight:0', 'h_._9/mlp/c_proj/bias:0', 'h_._7/attn/c_proj/bias:0', 'h_._10/mlp/c_proj/weight:0', 'h_._10/mlp/c_proj/bias:0', 'h_._3/ln_1/gamma:0', 'h_._8/attn/c_proj/weight:0', 'ln_f/beta:0', 'h_._5/ln_1/beta:0', 'h_._11/ln_1/gamma:0', 'h_._8/ln_1/beta:0', 'h_._10/attn/c_attn/weight:0', 'h_._0/attn/c_attn/bias:0', 'h_._10/mlp/c_fc/weight:0', 'h_._5/ln_1/gamma:0', 'h_._11/ln_2/beta:0', 'h_._2/mlp/c_proj/weight:0', 'h_._7/mlp/c_proj/weight:0', 'h_._3/attn/c_attn/weight:0', 'h_._8/mlp/c_proj/bias:0', 'h_._10/attn/c_proj/bias:0', 'h_._7/attn/c_attn/weight:0', 'h_._9/ln_2/beta:0', 'h_._7/ln_2/beta:0', 'h_._8/attn/c_proj/bias:0', 'h_._8/mlp/c_fc/bias:0', 'h_._1/mlp/c_fc/bias:0', 'h_._6/ln_2/beta:0', 'h_._10/ln_1/gamma:0', 'h_._11/attn/c_attn/bias:0', 'h_._3/mlp/c_proj/weight:0', 'h_._1/attn/c_proj/bias:0', 'h_._2/ln_1/beta:0', 'wpe/embeddings:0', 'h_._6/attn/c_proj/bias:0', 'h_._10/attn/c_attn/bias:0', 'h_._5/mlp/c_proj/weight:0', 'h_._6/ln_1/beta:0', 'h_._11/attn/c_proj/weight:0', 'h_._11/mlp/c_fc/bias:0', 'h_._1/ln_1/gamma:0', 'h_._10/ln_2/beta:0', 'h_._8/attn/c_attn/weight:0', 'h_._4/mlp/c_fc/bias:0', 'h_._0/mlp/c_proj/weight:0', 'h_._7/ln_1/beta:0', 'h_._9/attn/c_proj/weight:0', 'h_._4/attn/c_attn/bias:0', 'h_._6/mlp/c_fc/weight:0', 'h_._0/mlp/c_fc/bias:0', 'h_._5/mlp/c_fc/bias:0', 'h_._2/mlp/c_fc/bias:0', 'h_._4/attn/c_proj/bias:0', 'h_._1/ln_2/gamma:0', 'h_._5/attn/c_proj/weight:0', 'h_._6/mlp/c_proj/bias:0', 'h_._3/ln_2/gamma:0', 'h_._2/attn/c_attn/bias:0', 'h_._1/attn/c_attn/weight:0', 'h_._11/attn/c_proj/bias:0', 'h_._8/mlp/c_fc/weight:0', 'h_._11/ln_1/beta:0', 'h_._0/mlp/c_fc/weight:0', 'h_._11/mlp/c_proj/weight:0', 'h_._5/ln_2/beta:0', 'h_._9/ln_1/gamma:0', 'h_._5/mlp/c_fc/weight:0', 'h_._5/attn/c_attn/weight:0', 'h_._2/attn/c_proj/bias:0', 'h_._8/attn/c_attn/bias:0', 'h_._7/mlp/c_fc/weight:0', 'wte/weight:0', 'h_._2/mlp/c_fc/weight:0', 'h_._7/attn/c_attn/bias:0', 'h_._1/mlp/c_fc/weight:0', 'h_._4/ln_1/gamma:0', 'h_._2/attn/c_proj/weight:0', 'h_._5/ln_2/gamma:0', 'h_._5/attn/c_attn/bias:0', 'h_._3/mlp/c_fc/bias:0', 'h_._6/attn/c_proj/weight:0', 'h_._9/ln_2/gamma:0', 'h_._3/ln_2/beta:0', 'h_._8/ln_2/beta:0', 'h_._2/mlp/c_proj/bias:0', 'h_._11/mlp/c_proj/bias:0', 'h_._0/attn/c_proj/weight:0', 'h_._0/ln_2/gamma:0', 'h_._4/mlp/c_proj/bias:0', 'h_._6/attn/c_attn/bias:0', 'h_._10/ln_1/beta:0', 'h_._4/attn/c_attn/weight:0', 'h_._3/ln_1/beta:0', 'h_._9/attn/c_proj/bias:0', 'h_._2/ln_2/beta:0', 'h_._4/mlp/c_proj/weight:0', 'h_._2/ln_2/gamma:0', 'h_._6/mlp/c_fc/bias:0', 'h_._1/ln_1/beta:0', 'h_._2/ln_1/gamma:0', 'h_._4/mlp/c_fc/weight:0', 'h_._8/ln_1/gamma:0', 'h_._1/mlp/c_proj/bias:0', 'h_._9/attn/c_attn/bias:0', 'h_._11/ln_2/gamma:0', 'h_._8/ln_2/gamma:0', 'h_._10/attn/c_proj/weight:0', 'h_._11/mlp/c_fc/weight:0', 'h_._7/mlp/c_proj/bias:0', 'h_._7/ln_2/gamma:0', 'h_._4/attn/c_proj/weight:0', 'h_._7/ln_1/gamma:0', 'h_._5/mlp/c_proj/bias:0', 'h_._3/attn/c_attn/bias:0', 'h_._0/ln_1/beta:0', 'h_._3/attn/c_proj/weight:0', 'h_._11/attn/c_attn/weight:0', 'h_._0/mlp/c_proj/bias:0', 'h_._2/attn/c_attn/weight:0', 'h_._1/mlp/c_proj/weight:0', 'h_._1/ln_2/beta:0', 'h_._0/ln_2/beta:0', 'h_._3/mlp/c_fc/weight:0', 'h_._1/attn/c_proj/weight:0', 'h_._6/mlp/c_proj/weight:0', 'h_._9/ln_1/beta:0', 'h_._7/mlp/c_fc/bias:0', 'ln_f/gamma:0', 'h_._3/attn/c_proj/bias:0', 'h_._3/mlp/c_proj/bias:0', 'h_._9/mlp/c_fc/bias:0', 'h_._0/ln_1/gamma:0', 'h_._4/ln_2/beta:0', 'h_._9/attn/c_attn/weight:0', 'h_._7/attn/c_proj/weight:0', 'h_._10/mlp/c_fc/bias:0', 'h_._1/attn/c_attn/bias:0', 'h_._6/ln_1/gamma:0', 'h_._4/ln_1/beta:0', 'h_._9/mlp/c_fc/weight:0', 'h_._4/ln_2/gamma:0', 'h_._9/mlp/c_proj/weight:0', 'h_._6/ln_2/gamma:0']
- This IS expected if you are initializing TFGPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing TFGPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some layers of TFGPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['tfgp_t2model_1/transformer/h_._7/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._10/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._8/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._6/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._8/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._9/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._0/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._10/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._6/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._6/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/wte/weight:0', 'tfgp_t2model_1/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._11/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._9/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._9/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._9/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._7/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._0/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._10/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._10/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._8/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._7/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._8/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._9/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._6/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._11/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._4/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._9/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._10/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._11/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._8/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._9/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._11/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._7/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._11/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._6/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._8/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._8/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._5/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._11/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._3/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._9/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._6/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._8/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._1/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._10/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._7/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._6/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._6/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._4/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._7/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/wpe/embeddings:0', 'tfgp_t2model_1/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._2/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._2/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._3/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._10/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._11/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._6/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._0/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._9/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._10/ln_1/gamma:0', 'tfgp_t2model_1/transformer/ln_f/gamma:0', 'tfgp_t2model_1/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._7/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._0/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._7/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._8/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._10/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._11/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._0/ln_2/beta:0', 'tfgp_t2model_1/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._8/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._11/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._8/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._9/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._7/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._10/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._9/ln_2/gamma:0', 'tfgp_t2model_1/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._7/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._7/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._10/mlp/c_fc/weight:0', 'tfgp_t2model_1/transformer/h_._5/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._10/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._6/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._1/ln_1/beta:0', 'tfgp_t2model_1/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._6/attn/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._11/attn/c_attn/weight:0', 'tfgp_t2model_1/transformer/h_._11/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._11/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/ln_f/beta:0', 'tfgp_t2model_1/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2model_1/transformer/h_._7/mlp/c_proj/weight:0', 'tfgp_t2model_1/transformer/h_._9/mlp/c_proj/bias:0', 'tfgp_t2model_1/transformer/h_._8/attn/c_attn/bias:0', 'tfgp_t2model_1/transformer/h_._6/mlp/c_fc/bias:0', 'tfgp_t2model_1/transformer/h_._3/attn/c_proj/weight:0']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Starting training run gpt2-2020-11-03-16-43-13 of model GPT2Model with following hypers:
{'code_token_vocab_size': 50257, 'code_token_vocab_count_threshold': 1024, 'code_token_embedding_size': 768, 'code_use_subtokens': False, 'code_mark_subtoken_end': False, 'code_max_num_tokens': 200, 'code_use_bpe': True, 'code_pct_bpe': 0.5, 'code_self_attention_activation': 'gelu_new', 'code_self_attention_hidden_size': 768, 'code_self_attention_intermediate_size': 768, 'code_self_attention_num_layers': 12, 'code_self_attention_num_heads': 12, 'code_self_attention_pool_mode': 'weighted_mean', 'query_token_vocab_size': 50257, 'query_token_vocab_count_threshold': 1024, 'query_token_embedding_size': 768, 'query_use_subtokens': False, 'query_mark_subtoken_end': False, 'query_max_num_tokens': 30, 'query_use_bpe': True, 'query_pct_bpe': 0.5, 'query_self_attention_activation': 'gelu_new', 'query_self_attention_hidden_size': 768, 'query_self_attention_intermediate_size': 768, 'query_self_attention_num_layers': 12, 'query_self_attention_num_heads': 12, 'query_self_attention_pool_mode': 'weighted_mean', 'batch_size': 450, 'optimizer': 'Adam', 'seed': 0, 'dropout_keep_rate': 0.9, 'learning_rate': 0.0005, 'learning_rate_code_scale_factor': 1.0, 'learning_rate_query_scale_factor': 1.0, 'learning_rate_decay': 0.98, 'momentum': 0.85, 'gradient_clip': 1, 'loss': 'softmax', 'margin': 1, 'max_epochs': 2, 'patience': 5, 'fraction_using_func_name': 0.1, 'min_len_func_name_for_query': 12, 'query_random_token_frequency': 0.0}
Loading training and validation data.
Begin Training.
Training on 30000 python samples.
Validating on 23107 python samples.
2020-11-03 16:47:08.248525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.310312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-11-03 16:47:08.310520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-03 16:47:08.310623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-11-03 16:47:08.310713: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-03 16:47:08.310819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-03 16:47:08.310934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-03 16:47:08.311052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-03 16:47:08.311157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-03 16:47:08.311477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.312375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.312995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-11-03 16:47:08.688644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.689443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-11-03 16:47:08.689539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-03 16:47:08.689625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-11-03 16:47:08.689692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-03 16:47:08.689752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-03 16:47:08.689808: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-03 16:47:08.689857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-03 16:47:08.689904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-03 16:47:08.690073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.690834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.691544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-11-03 16:47:08.826941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-03 16:47:08.827025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-11-03 16:47:08.827066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-11-03 16:47:08.827747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.828687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-03 16:47:08.829446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1338 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/dpu_utils/utils/debughelper.py", line 21, in run_and_debug
    func()
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/src/train.py", line 199, in <lambda>
    run_and_debug(lambda: run(args), args['--debug'])
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/src/train.py", line 185, in run
    parallelize=not(arguments['--sequential']))
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/src/train.py", line 97, in run_train
    model_path = model.train(train_data, valid_data, azure_info_path, quiet=quiet, resume=resume)
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/src/models/model.py", line 776, in train
    self.__sess.run(init_op)
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 958, in run
    run_metadata_ptr)
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1166, in _run
    self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 477, in __init__
    self._fetch_mapper = _FetchMapper.for_fetch(fetches)
  File "/mnt/34C28480C28447D6/PycharmProjects/semantic-code-search-tf2/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 263, in for_fetch
    (fetch, type(fetch)))
TypeError: Fetch argument None has invalid type <class 'NoneType'>
